<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Team 01 - About the Project</title>
    <!-- Theme CSS -->
    <link rel="stylesheet" href="../static/assets/css/main.css" />
    <!-- Custom CSS -->
    <link rel="stylesheet" href="../static/assets/css/custom.css" />
    <link
    rel="icon"
    type="image/x-icon"
    href="../static/assets/css/images/favicon.ico"
  />
    <noscript
      ><link rel="stylesheet" href="../static/assets/css/noscript.css"
    /></noscript>
    <!-- Include MathJax for LaTeX rendering (Optional, keep if needed) -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [["\\(", "\\)"]],
          displayMath: [["$$", "$$"]],
          processEscapes: true,
          processEnvironments: true,
        },
        options: {
          skipHtmlTags: ["script", "noscript", "style", "textarea", "pre"],
        },
      };
    </script>
    <script
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
      id="MathJax-script"
      async
    ></script>
  </head>
  <body class="is-preload landing">
    <div id="page-wrapper">
      <!-- Header -->
      <header id="header">
        <!-- Ensure logo links correctly to index.html in the root -->
        <h1 id="logo"><a href="../index.html">Team 01</a></h1>
        <nav id="nav">
          <ul>
            <!-- Use relative paths from the 'about' directory -->
            <li><a href="../index.html">Home</a></li>
            <li><a href="../about/about.html">About</a></li>
            <li><a href="../gallery/code_explaination.html">Code</a></li>
            <li><a href="../gallery/data.html">Data</a></li>
            <li><a href="../gallery/gallery_images.html">Gallery</a></li>
            <li>
              <a
                href="https://github.com/RAS598-2025-S-Team01/RAS598-2025-S-Team01.github.io"
                class="button primary"
                target="_blank"
                rel="noopener noreferrer"
                >Github</a
              >
            </li>
          </ul>
        </nav>
      </header>

      <!-- Main Content -->
      <section id="main" class="wrapper style1">
        <div class="container">
          <header class="major">
            <h2>About the Project: Fusion Robotics</h2>
            <p>Detailed description of our Quadruped-UR5 Robotics Testbed.</p>
          </header>

          <!-- Section 1: Updated Project Description -->
          <!-- This section will be animated by custom.js -->
          <section id="description">
            <h3>1. Description & Scope</h3>
            <p>
              Our project, "Fusion Robotics," establishes an autonomous testbed
              integrating a quadruped robot and a UR5 robotic arm, orchestrated
              using ROS 2. The core objective is to create a repeatable,
              automated workflow for testing quadruped locomotion, collecting
              sensor data, and evaluating performance through a closed loop
              involving real-world execution and analysis.
            </p>

            <h4>1.1 Project Scoping and Evolution</h4>
            <p>
              Initially, our project broadly aimed to explore sensor fusion for
              optimizing experimental setups. Through the initial development
              cycles (Weeks 7-12), involving individual component testing (UR5
              control, quadruped basic motion, sensor readings), we identified
              the critical need to first solidify the core autonomous workflow.
              Therefore, our scope refined to prioritize the seamless
              integration and interaction between the UR5 and the quadruped for
              the automated reset sequence. This became the primary milestone,
              ensuring a stable platform before delving deeper into complex
              simulation comparisons or advanced SLAM implementations initially
              envisioned. The focus shifted towards robust hardware integration,
              real-time control via a user interface, and reliable data
              acquisition through ROS 2.
            </p>

            <h4>1.2 Data Collection Process</h4>
            <p>
              Our data collection process is central to the experimental loop:
            </p>
            <ol>
              <li>
                <strong>Initialization:</strong> The UR5 arm precisely places
                the quadruped robot at a designated starting position.
              </li>
              <li>
                <strong>Autonomous Locomotion:</strong> Triggered via our ROS 2
                system (potentially through the UI), the quadruped begins
                walking forward based on pre-set or user-defined gait parameters
                (See Section 4).
              </li>
              <li>
                <strong>Real-time Sensing:</strong> As the quadruped moves, its
                onboard sensors (IMU, Camera - providing data for
                <code>/orb/pose</code>, Servo encoders) continuously publish
                data to respective ROS 2 topics.
              </li>
              <li>
                <strong>Data Logging & Visualization:</strong> A dedicated ROS 2
                node (<code>/ros2_flask_plotter</code>) subscribes to these
                topics, logging the data and visualizing key metrics (IMU
                readings, pose estimates) in real-time via a web interface.
              </li>
              <li>
                <strong>Path Completion & Reset:</strong> Upon reaching a
                predefined distance or condition (monitored via pose
                estimation), the quadruped stops. A signal is sent (potentially
                automated or via UI) to the UR5 arm.
              </li>
              <li>
                <strong>Automated Reset:</strong> The UR5 executes a
                pre-programmed routine to pick up the quadruped and return it to
                the starting position.
              </li>
              <li>
                <strong>Iteration:</strong> The cycle repeats, allowing for
                continuous data collection under varying parameters or
                conditions.
              </li>
            </ol>
            <p>
              Initial data collection involved testing sensors individually and
              calibrating the quadruped's basic movements. This data was crucial
              for tuning low-level controllers and identifying necessary
              filtering techniques. We found raw IMU data too noisy due to motor
              vibrations, necessitating filtering. Early camera pose tests
              highlighted sensitivity to lighting, guiding our focus towards
              robust estimation methods. This iterative process of
              collect-analyze-refine was essential and required revisiting
              initial data assumptions.
            </p>

            <h4>1.3 Pose Estimation and Model Fitting</h4>
            <p>
              Accurate pose estimation is vital for path completion detection
              and performance analysis. We employ multiple approaches:
            </p>
            <ul>
              <li>
                <strong>IMU-based Pose Estimation:</strong> The
                <code>/pose_estimator_node</code> integrates data from
                <code>/imu/data</code> and <code>/imu/orientation</code> (likely
                using techniques like Kalman filtering or complementary filters)
                to produce <code>/imu/pose_estimate</code>. This provides a
                continuous estimate of the robot's orientation and potentially
                position relative to its start.
              </li>
              <li>
                <strong>Camera-based Pose Estimation:</strong> The
                <code>/optical_flow_pose_publisher</code> node processes camera
                data (likely visual features or optical flow) to publish pose
                information on the <code>/orb/pose</code> topic. This offers an
                alternative, potentially drift-correcting pose source,
                especially useful for tracking position over ground.
              </li>
              <li>
                <strong>Sensor Fusion (Implicit/Comparative):</strong> While the
                current ROS graph doesn't show explicit fusion of
                <code>/imu/pose_estimate</code> and <code>/orb/pose</code> into
                a single topic, our web interface plots both. This allows for
                direct comparison and validation. Future work could involve
                fusing these using filters (e.g., Extended Kalman Filter) for a
                more robust estimate. Data collected informs the tuning of these
                estimators (e.g., filter noise parameters).
              </li>
            </ul>

            <h4>1.4 Integration into ROS 2</h4>
            <p>
              The entire system is orchestrated using ROS 2 Humble. The
              quadruped itself is integrated via the <code>/bridge_node</code>,
              which translates high-level commands and parameter changes into
              low-level <code>/servo/command</code> messages and publishes
              <code>/servo/state</code>. Sensor data is published directly by
              dedicated nodes or drivers (e.g., IMU node, camera node publishing
              to <code>/orb/pose</code>). A Flask web server
              (<code>/ros2_flask_plotter</code>) acts as the central UI,
              subscribing to relevant topics for visualization and potentially
              publishing commands or parameter updates. (See Section 4 for the
              detailed architecture).
            </p>

            <h4>1.5 Validation and Success Metrics</h4>
            <p>We quantify success through several metrics:</p>
            <ul>
              <li>
                <strong>Workflow Completion:</strong> Successfully executing
                multiple consecutive cycles of the walk-and-reset loop
                autonomously.
              </li>
              <li>
                <strong>Pose Estimation Accuracy:</strong> Comparing
                <code>/imu/pose_estimate</code> and <code>/orb/pose</code>.
                While ground truth from OptiTrack (as mentioned in original
                goals) might not be fully integrated yet, we assess consistency,
                drift characteristics, and agreement between the methods.
                Graphical plots showing the time evolution of both estimates are
                used for visual validation.
              </li>
              <li>
                <strong>Control Responsiveness:</strong> Demonstrating real-time
                changes in quadruped gait parameters (Frequency, Duty Factor,
                Amplitudes, Offsets, Mode) via the web UI and observing the
                corresponding immediate change in locomotion.
              </li>
              <li>
                <strong>Data Integrity:</strong> Ensuring sensor data logged via
                the <code>/ros2_flask_plotter</code> is consistent and reflects
                the robot's state accurately.
              </li>
            </ul>
            <figure>
              <!-- [PLACEHOLDER: Insert screenshot of your web UI showing plots] -->
              <img
                class="responsive"
                src="https://drive.google.com/thumbnail?id=1K5av9xoC7nrwIB3XXrLIk6M40THacZq-&sz=w1000"
                alt="Web UI showing sensor data and pose estimates"
              />

              <figcaption>
                Figure 1: Real-time visualization of IMU data and comparative
                pose estimates via the web interface.
              </figcaption>
            </figure>
          </section>

          <!-- Section 2: Updated Project Goals -->
          <!-- This section will be animated by custom.js -->
          <section id="goals">
            <h3>2. Updated Project Goals</h3>
            <p>
              Our core vision of creating an advanced, automated robotic testbed
              remains. However, based on initial development and feasibility
              assessments, our project goals have been refined since the
              beginning:
            </p>
            <ul>
              <li>
                <strong>Original Goal:</strong> Develop a testbed optimizing
                experimental accuracy via sensor fusion and simulation
                comparisons.
              </li>
              <li>
                <strong>Updated & Current Goals:</strong>
                <ol>
                  <li>
                    <strong>Demonstrate a Fully Autonomous Workflow:</strong>
                    Successfully implement and showcase the closed-loop system
                    where the UR5 positions the quadruped, the quadruped walks
                    autonomously while collecting data, and the UR5 resets it
                    for continuous operation.
                  </li>
                  <li>
                    <strong
                      >Implement Real-Time Quadruped Control via UI:</strong
                    >
                    Provide a user-friendly web interface (Flask-based) that
                    allows real-time monitoring of sensor data (IMU, Pose
                    Estimates) and interactive control over the quadruped's gait
                    parameters (Frequency, Duty Factor, Offsets, Amplitudes) and
                    movement modes (Walk, Trot, Pronk, etc.).
                  </li>
                  <li>
                    <strong
                      >Integrate and Compare Pose Estimation Methods:</strong
                    >
                    Utilize and log pose estimates derived from the IMU
                    (<code>/imu/pose_estimate</code>) and camera-based methods
                    (<code>/orb/pose</code>), enabling comparison and analysis
                    of their performance within our specific setup.
                  </li>
                  <li>
                    <strong>Develop Robust ROS 2 Integration:</strong> Create a
                    modular and reliable ROS 2 architecture connecting the UR5
                    (control assumed via existing ROS drivers/custom scripts),
                    the quadruped (via <code>/bridge_node</code>), sensors,
                    estimation nodes, and the user interface.
                  </li>
                  <li>
                    <strong>Provide Open Resources:</strong> Share our developed
                    ROS 2 packages, setup instructions, and collected
                    experimental data to benefit the robotics community (as
                    originally planned).
                  </li>
                </ol>
              </li>
            </ul>
            <p>
              The emphasis has shifted from deep simulation integration within
              this semester to proving the core hardware automation, real-time
              control, and multi-sensor data handling pipeline first.
            </p>
          </section>

          <!-- Section 3: Project Process / Workflow -->
          <!-- This section will be animated by custom.js -->
          <section id="workflow">
            <h3>3. Project Process / Workflow</h3>
            <p>
              Our project workflow follows an iterative development process
              within the ROS 2 ecosystem. The high-level plan remains similar,
              but the <em>focus</em> within the later weeks shifted towards
              integration and UI development.
            </p>
            <p>
              <strong>Note:</strong> While the overall weekly themes remain
              similar to the initial plan, Weeks 12-15 saw an increased focus on
              developing the <code>bridge_node</code> for parameter control, the
              <code>ros2_flask_plotter</code> UI, and achieving the core
              UR5-Quadruped automated reset loop, deferring deeper simulation
              comparisons.
            </p>

            <h4>Project Timeline (Weeks 7-16)</h4>
            <div class="table-wrapper">
              <!-- Use table-wrapper for theme styling -->
              <table>
                <thead>
                  <tr>
                    <th>Week</th>
                    <th>Task</th>
                    <th>Status Notes</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>7</td>
                    <td>
                      Initialize UR5 for positioning the quadruped at the start
                      point
                    </td>
                    <td>Completed</td>
                  </tr>
                  <tr>
                    <td>8</td>
                    <td>Validate communication between UR5 and host machine</td>
                    <td>Completed</td>
                  </tr>
                  <tr>
                    <td>9</td>
                    <td>Quadruped calibration and mobility tuning</td>
                    <td>Completed</td>
                  </tr>
                  <tr>
                    <td>10</td>
                    <td>
                      Initiate quadruped hardware setup; basic mobility tests
                    </td>
                    <td>Completed. Initial ROS topic publishing setup.</td>
                  </tr>
                  <tr>
                    <td>11</td>
                    <td>Fine-tune mechanical alignment and sensor mounts</td>
                    <td>Completed. Focused on IMU/Camera mounting.</td>
                  </tr>
                  <tr>
                    <td>12</td>
                    <td>
                      Quadruped ROS Node Dev (<code>/bridge_node</code>,
                      parameters)
                    </td>
                    <td>Completed. Basic parameter control achieved.</td>
                  </tr>
                  <tr>
                    <td>13</td>
                    <td>
                      Develop UI (<code>/ros2_flask_plotter</code>) & Pose
                      Estimation
                    </td>
                    <td>Completed. UI plots data, basic control added.</td>
                  </tr>
                  <tr>
                    <td>14</td>
                    <td>Integrate UR5 control logic with Quadruped state</td>
                    <td>Completed. Core automation loop functional.</td>
                  </tr>
                  <tr>
                    <td>15</td>
                    <td>Full system integration & robustness testing</td>
                    <td>Completed. Tested walk-reset cycle multiple times.</td>
                  </tr>
                  <tr>
                    <td>16</td>
                    <td>Final Demo Prep, Documentation, Code Packaging</td>
                    <td>Completed.</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </section>

          <!-- Section 4: Finalized ROS 2 Architecture -->
          <section id="ros">
            <h3>4. Finalized System & ROS 2 Architecture</h3>

            <p>
              Our system leverages ROS 2 Humble for modular communication
              between the hardware components, control logic, and user
              interface. The architecture is designed for clarity and
              extensibility.
            </p>
            <figure>
              <!-- [PLACEHOLDER: Insert your vector-based ROS graph image here] -->
              <img
                class="responsive"
                src="https://drive.google.com/thumbnail?id=19ztdmX9D2rtsbJV15LfoqSZtRVrkrm3x&sz=w1000"
                alt="ROS 2 Node and Topic Architecture"
              />

              <figcaption>
                Figure 2: Finalized ROS 2 Node and Topic Architecture
              </figcaption>
            </figure>

            <h4>Key Components:</h4>
            <ul>
              <li>
                <strong>Nodes (Ellipses/Rectangles in Diagram):</strong>
                <ul>
                  <li>
                    <code>/bridge_node</code> (Dark Grey): Interfaces directly
                    with the quadruped's hardware (servos). Subscribes to
                    <code>/servo/command</code> and parameter updates. Publishes
                    <code>/servo/state</code>. Handles gait generation based on
                    parameters.
                  </li>
                  <li>
                    <code>/pose_estimator_node</code> (Purple): Subscribes to
                    <code>/imu/data</code>, <code>/imu/orientation</code>.
                    Performs calculations (e.g., sensor fusion, integration) and
                    publishes <code>/imu/pose_estimate</code>.
                  </li>
                  <li>
                    <code>/optical_flow_pose_publisher</code> (Teal): Processes
                    camera data (implied input) using optical flow/visual
                    features. Publishes pose to <code>/orb/pose</code>.
                  </li>
                  <li>
                    <code>/ros2_flask_plotter</code> (Pink): Bridge between ROS
                    2 and the web UI. Subscribes to sensor/state topics
                    (<code>/imu/*</code>, <code>/orb/pose</code>,
                    <code>/servo/state</code>) for visualization. Hosts
                    services/publishers for UI commands and parameter changes
                    (possibly via <code>/parameter_events</code>).
                  </li>
                  <li>
                    <em>(Implied Nodes):</em> Sensor driver nodes publishing raw
                    data (IMU, Camera), UR5 control node.
                  </li>
                </ul>
              </li>
              <li>
                <strong
                  >Topics (Arrows connecting Nodes, grouped by
                  namespaces):</strong
                >
                <ul>
                  <li>
                    <code>/imu/data</code> (Yellow): Raw IMU
                    accelerometer/gyroscope data.
                  </li>
                  <li>
                    <code>/imu/orientation</code> (Yellow): Filtered IMU
                    orientation (e.g., quaternions).
                  </li>G
                  <li>
                    <code>/imu/pose_estimate</code> (Yellow): Calculated pose
                    from IMU data (by <code>/pose_estimator_node</code>).
                  </li>
                  <li>
                    <code>/orb/pose</code> (Teal): Calculated pose from
                    camera/visual data (by
                    <code>/optical_flow_pose_publisher</code>).
                  </li>
                  <li>
                    <code>/servo/command</code> (Red): Commands sent to
                    quadruped servos (by <code>/bridge_node</code>).
                  </li>
                  <li>
                    <code>/servo/state</code> (Red): Current state from servos
                    (published by <code>/bridge_node</code>).
                  </li>
                  <li>
                    <code>/parameter_events</code> (Grey): Standard ROS 2 topic
                    for parameter changes.
                  </li>
                  <li>
                    <code>/rosout</code> (Grey): Standard ROS 2 logging topic.
                  </li>
                </ul>
              </li>
            </ul>

            <h4>Quadruped Control Parameters (via UI):</h4>
            <div class="table-wrapper">
              <table>
                <thead>
                  <tr>
                    <th>Parameter</th>
                    <th>Description</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>F</td>
                    <td>Frequency of oscillation (controls step speed)</td>
                  </tr>
                  <tr>
                    <td>DF</td>
                    <td>Duty factor (portion of cycle foot is on ground)</td>
                  </tr>
                  <tr>
                    <td>FO</td>
                    <td>Foot Offset (lateral position offset)</td>
                  </tr>
                  <tr>
                    <td>EO</td>
                    <td>Elbow Offset (adjusts elbow position offset)</td>
                  </tr>
                  <tr>
                    <td>HA</td>
                    <td>Hip Amplitude (range of hip joint movement)</td>
                  </tr>
                  <tr>
                    <td>HO</td>
                    <td>Hip Offset (base angle shift for hip joint)</td>
                  </tr>
                  <tr>
                    <td>KA</td>
                    <td>Knee Amplitude (range of knee joint movement)</td>
                  </tr>
                  <tr>
                    <td>KO</td>
                    <td>Knee Offset (base angle shift for knee joint)</td>
                  </tr>
                  <tr>
                    <td>Movement Mode</td>
                    <td>Gait selection: PRONK, WALK, PACE, TROT, BOUND</td>
                  </tr>
                </tbody>
              </table>
            </div>

            <!-- START: Inserted Carousel Block -->
            <div class="system-architecture-visuals">
              <!-- Wrapper div -->
              <header class="major" style="text-align: center; margin-top: 3em">
                <!-- Centered header -->
                <h4>System Architecture Visualization</h4>
                <p>
                  Interact with the diagram or view the static architecture.
                </p>
              </header>

              <div class="carousel-container">
                <!-- Slide 1: Full animated diagram -->
                <div class="carousel-slide active">
                  <!-- Start with this slide active -->
                  <div class="carousel-content">
                    <div class="diagram-wrapper">
                      <svg id="arrow-canvas"></svg>
                      <!-- SVG for arrows -->
                      <!-- Inside the .carousel-slide .diagram-wrapper -->
                      <div class="quad-cluster">
                        <img
                          id="quadrupedImg"
                          src="https://drive.google.com/thumbnail?id=10klM3L3n3x_vw4EgEcuV2vT4hs8_cRaX&sz=w1000"
                          alt="Quadruped"
                        />

                        <div id="quadStatus">Initializing...</div>
                        <!-- Plots are now direct children -->
                        <div class="block animated-plot" id="imu-plot">
                          <canvas
                            id="imuCanvas"
                            width="180"
                            height="80"
                          ></canvas>
                          <div class="label">IMU Pose</div>
                        </div>
                        <div
                          class="block animated-camera-plot"
                          id="camera-pose"
                        >
                          <canvas
                            id="cameraCanvas"
                            width="180"
                            height="80"
                          ></canvas>
                          <div class="label">Camera Pose</div>
                        </div>
                      </div>

                      <div class="block" id="ur5">
                        <img src="https://drive.google.com/thumbnail?id=1CQ75fRtXiswbmohswEaEV3oaMW5gM5eM" alt="UR5e" />
                        <!-- Corrected Path -->
                        <div class="label">UR5e Arm</div>
                      </div>
                    </div>
                  </div>
                </div>

                <!-- Slide 2: Explanation image -->
                <div class="carousel-slide">
                  <div class="carousel-content">
                    <!-- Removed inner diagram-wrapper for static image -->
                    <img
                      src="https://drive.google.com/thumbnail?id=1dYZ5xaMBLFVqCS3U3Kqw6w07qXZdJIAk&sz=w1000"
                      alt="System Architecture Overview"
                      class="carousel-full-image"
                    />
                  
                  </div>
                </div>

                <!-- Carousel Buttons -->
                <!-- Note: onclick requires changeSlide function in custom.js -->
                <button class="carousel-btn prev" aria-label="Previous Slide">
                  &#10094;
                </button>
                <button class="carousel-btn next" aria-label="Next Slide">
                  &#10095;
                </button>
              </div>
            </div>
            <!-- END: Inserted Carousel Block -->

            <h4>Data Flow Example (Control):</h4>
            <ol>
              <li>User changes 'Frequency' parameter on the Web UI.</li>
              <li>
                UI sends command via Flask backend to
                <code>/ros2_flask_plotter</code>.
              </li>
              <li>
                <code>/ros2_flask_plotter</code> updates the relevant parameter
                on <code>/bridge_node</code> (e.g., via parameter service call
                or <code>/parameter_events</code>).
              </li>
              <li>
                <code>/bridge_node</code> receives the parameter update, adjusts
                its internal gait generator logic.
              </li>
              <li>
                <code>/bridge_node</code> publishes new joint targets on
                <code>/servo/command</code>.
              </li>
              <li>Quadruped hardware responds to new commands.</li>
              <li>
                Changes in motion affect <code>/imu/*</code> and
                <code>/orb/pose</code> data, which are visualized back on the UI
                via <code>/ros2_flask_plotter</code>.
              </li>
            </ol>
          </section>

      <!-- Section 5: System Tradeoffs -->
      <!-- This section will be animated by custom.js -->
      <section id="tradeoffs">
        <h3>5. System Tradeoffs & Technical Considerations</h3>
        <p>
          Engineering this integrated robotic system involved balancing key technical
          requirements:
        </p>
        <ol>
          <li>
            <strong>Pose Estimation: Accuracy vs. Resources</strong>
            <ul>
              <li>
                <strong>Conflict:</strong> High-accuracy SLAM demands significant
                computation (CPU/RAM), conflicting with real-time needs on potentially
                limited onboard hardware. Basic IMU integration is fast but drifts
                significantly.
              </li>
              <li>
                <strong>Balance:</strong> Implemented parallel, independent IMU-based
                (fast filter, drift-prone position) and camera-based
                (<code>/orb/pose</code>, likely VO, less drift, higher latency/load)
                estimators. Deferred complex real-time fusion; enabled comparison via
                UI.
              </li>
              <li>
                <strong>Implication:</strong> Provides redundancy and comparison data
                but relies on simpler/less optimal estimates for real-time control
                logic or requires offline analysis for best accuracy.
              </li>
            </ul>
          </li>
          <li>
            <strong>Real-time Control vs. Stability</strong>
            <ul>
              <li>
                <strong>Conflict:</strong> Instantaneous UI changes to gait parameters
                (frequency, amplitude) can command dynamically unstable states for the
                quadruped.
              </li>
              <li>
                <strong>Balance:</strong> Used ROS 2 parameters managed via the UI.
                The <code>/bridge_node</code> likely applies rate limiting, value
                clamping, and/or input smoothing to parameter changes before
                generating servo commands.
              </li>
              <li>
                <strong>Implication:</strong> Prioritizes robot stability and safety
                over immediate command response, resulting in smoother, controlled
                transitions.
              </li>
            </ul>
          </li>
          <li>
            <strong>Hardware Constraints vs. Algorithm Choice</strong>
            <ul>
              <li>
                <strong>Conflict:</strong> Onboard computing limits (e.g., Raspberry
                Pi) restrict the feasibility of running complex algorithms like full
                SLAM or MPC concurrently with control loops.
              </li>
              <li>
                <strong>Balance:</strong> Focused on core functionality using
                performant, established ROS 2 packages and less demanding algorithms
                (e.g., filters/VO instead of full SLAM). Deferred resource-intensive
                features.
              </li>
              <li>
                <strong>Implication:</strong> Achieved reliable core operation on
                target hardware, but performance ceilings (accuracy, speed) may be
                lower than systems with high-end compute.
              </li>
            </ul>
          </li>
          <li>
            <strong>Development Time vs. Feature Scope</strong>
            <ul>
              <li>
                <strong>Conflict:</strong> Limited time required prioritizing core
                features over implementing the full initial vision (e.g., deep
                simulation, advanced fusion).
              </li>
              <li>
                <strong>Balance:</strong> Focused on delivering the Minimum Viable
                System: the robust automated walk-reset loop, multi-sensor data
                pipeline, interactive UI control, and comparative pose estimation.
              </li>
              <li>
                <strong>Implication:</strong> Delivered a functional, integrated
                testbed demonstrating the core concept, providing a validated platform
                for future, more advanced feature integration.
              </li>
            </ul>
          </li>
          <li>
            <strong>Path End Detection: Robustness vs. Precision (Type I & Type II Error)</strong>
            <ul>
              <li>
                <strong>Conflict:</strong> Stopping the quadruped accurately using
                noisy/drifting pose estimates risks stopping too early (Type I error)
                or overshooting the UR5 pickup zone (Type II error).
              </li>
              <li>
                <strong>Balance:</strong> Prioritized successful automated resets.
                Employed conservative stopping logic (e.g., filtering/hysteresis on
                pose estimate, slightly shorter target distance) and a generous UR5
                pickup envelope.
              </li>
              <li>
                <strong>Implication:</strong> High reliability in the autonomous loop,
                minimizing collision/failure risk, at the cost of potentially slightly
                shorter travel distances per run.
              </li>
            </ul>
          </li>
        </ol>
      </section>

      <ul class="actions special" id="navigation-button">
        <li>
          <a href="../index.html" class="button primary">Previous: Home</a>
        </li>
        <li>
          <a href="../gallery/code_explaination.html" class="button primary">Next: Code</a>
        </li>
      </ul>

    </div> <!-- Closing tag for #page-wrapper -->

    <!-- NEW FOOTER - MOVED OUTSIDE #page-wrapper -->
    <footer class="md-footer">
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        <!-- Removed Previous/Next Links -->
      </nav>

      <div class="md-footer-meta md-typeset">
        <div class="md-footer-meta__inner md-grid">
          <div class="md-copyright">
            <div class="md-copyright__highlight">
              Copyright &copy; 2024 RAS598-2025-S-Team01
            </div>
            <!-- Added HTML5 UP attribution -->
            <div>
              Design: <a href="http://html5up.net">HTML5 UP</a> | Course:
              RAS598 S2025, ASU
            </div>
          </div>
        </div>
      </div>
    </footer>
    <!-- END NEW FOOTER -->

    <!-- Scripts -->
    <!-- Theme Scripts FIRST -->
    <script src="../static/assets/js/jquery.min.js"></script>
    <script src="../static/assets/js/jquery.scrolly.min.js"></script>
    <script src="../static/assets/js/jquery.dropotron.min.js"></script>
    <script src="../static/assets/js/jquery.scrollex.min.js"></script>
    <script src="../static/assets/js/browser.min.js"></script>
    <script src="../static/assets/js/breakpoints.min.js"></script>
    <script src="../static/assets/js/util.js"></script>
    <script src="../static/assets/js/main.js"></script>
    <!-- Your Custom Script LAST -->
    <script src="../static/assets/js/custom.js"></script>
  </body>
</html>
